# 4강 선형 회귀분석

Property: Mar 04, 2020 1:07 PM

# 머신러닝에서의 선형회귀 모델

머신러닝에서는 training data 를 제일 잘 설명하는 직선을 찾는 것이 목적이다.

가장 좋은 모형을 선택하기 위해서는 적절한 모형, 적절한 데이터가 필요하다.

통계분석은 데이터를 나누지 않고 가설로 분석하지만,
머신러닝은 트레이닝 데이터와 테스트 데이터로 학습 → 검정을 거친다.
**데이터가 상대적으로 많아 가설이 필요없다.**

통계분석과 머신러닝의 가장 큰 차이는 **데이터 수** 라고 할 수 있다.

모형을 선택할 때, 데이터 그 자체를 보고 판단한다.

$$H(x) = Wx + b$$

H(x): 가설(Hypothesis), W: 가중치(Weight), B: 편의(Bias)

계쏙 W 와 B 를 바꿔가며 try, error 반복

## Cost(=Loss) function

구하는 가설과 실제 데이터와의 차이(잔차) ⇒ 머신러닝에서 Cost

$$(H(x) - y)^2$$

차이가 클 때는 Penalty(벌점)을 더 주고, 차이가 작으면 패널티를 상대적으로 덜 주기 때문에 비용을 계산하기에 효과적이다.

$$cost = \frac{1}{m}\sum_{i=1}^{m}(H(x^i) - y^i)^2$$

m : 트레이닝 데이터의 개수
i: 임의의 트레이닝 데이터 인덱스
H(x): x에서의 가설 상 예측 값
y: x에서의 실제 값

우리가 세운 가설과 실제 데이터가 얼마나 맞는지 확인한다.

W 와 b 의 값에 따라 cost 가 달라진다. 즉, Cost Function 은 W 와 b 에 대한 식이다.

### 어떻게 하면 Cost 를 최소화 할 수 있을까?

- Hypothesis and cost

$$H(x) = Wx + b$$

$$cost(W, b) = \frac{1}{m}\sum_{i=1}^{m}(H(x^i)-y^i)^2$$

- Simplified hypothesis

    $$H(x) = W(x)$$

    $$cost(W) = \frac{1}{m}\sum_{i=1}^{m}(W(x^i)-y^i)^2$$

W 를 계속 바꾸면서 Try & Error 과정을 거쳐 최소 Cost 를 선택한다.